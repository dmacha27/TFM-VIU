% INTRODUCCIÓN

\cleardoublepage

\chapter{Introducción}
\label{introduccion}

El aprendizaje automático o \textit{machine learning} como disciplina de la inteligencia artificial resulta ser uno de los campos más cotizados y que despierta más interés en prácticamente cualquier aplicación (investigación, automatización, sistemas de ayuda, detección...). Existe una división muy clara del aprendizaje automático que consta de: aprendizaje supervisado y el no supervisado. Pero existe otra división que no suele mencionarse, y que puede ser muy beneficiosa, este es el aprendizaje semi-supervisado.

De forma resumida, el aprendizaje supervisado trata de aprender de datos de los que se sabe lo que representan para después poder inferir este conocimiento para nuevos datos (por ejemplo, dadas las características de una flor, se intenta predecir de qué clase concreta es), el aprendizaje no supervisado trata de aprender de datos de los que \textbf{no} se sabe lo que representan, se utiliza en tareas en las que es necesario realizar agrupaciones o divisiones en base a las similitudes/disimilitudes de los ejemplos (por ejemplo, podría distinguir entre animales que tienen plumaje de los que no sin tener el conocimiento de qué animales son concretamente). En el caso del aprendizaje supervisado, el etiquetado de los datos suele ser un proceso costoso (es posible imaginar, por ejemplo, la cantidad de tiempo y recursos que podría suponer el etiquetado masivo de millones de muestras de posibles cánceres). En la realidad, la mayor parte de los datos no están etiquetados. Ante esta necesidad aparece el aprendizaje semi-supervisado, que se encuentra a caballo entre el supervisado y no supervisado y que permite aprovechar los escasos datos etiquetados para inferir su conocimiento a los no etiquetados.


\section{Conceptos teóricos}
\label{conceptos-teoricos}

En esta sección se expondrán los conceptos teóricos fundamentales del proyecto, los cuales abarcan el campo del aprendizaje automático, con un enfoque particular en el \destacado{aprendizaje semi-supervisado}.

\medskip

\subsection{Aprendizaje automático}

El aprendizaje automático (\textit{machine
learning}) según~\cite{intelligent:ml} es una rama de la Inteligencia Artificial y se trata de una técnica de análisis de datos que enseña a las computadoras a aprender de la \textbf{experiencia} (como los humanos). Para llevar a cabo este proceso, el aprendizaje automático requiere de una amplia cantidad de datos, o los necesarios para el problema específico en cuestión. Estos datos son procesados mediante algoritmos, los cuales se alimentan de ejemplos (también conocidos como instancias o prototipos). A través de estos ejemplos, los algoritmos tienen la capacidad de generalizar comportamientos ocultos.

Estos algoritmos mencionados mejoran su rendimiento iterativamente y de forma automática durante su entrenamiento e incluso también durante su aprovechamiento/explotación. El aprendizaje automático ha adquirido una gran relevancia en una amplia variedad de áreas como la visión artificial, automoción, detección de anomalías o automatización, entre otras. El aprendizaje automático generalmente se clasifica en tres tipos: aprendizaje supervisado, aprendizaje no supervisado y aprendizaje por refuerzo. Sin embargo, ha surgido una nueva disciplina que se sitúa entre el aprendizaje supervisado y el no supervisado, utilizando tanto datos etiquetados como no etiquetados durante el proceso de entrenamiento~\cite{vanEngelen2020}.

En la figura~\ref{fig:figuras/taxonomia.png} se presenta una clasificación del aprendizaje automático.

\imagen{figuras/taxonomia.png}{Clasificación de aprendizaje automático}{Clasificación de aprendizaje automático, basado en~\cite{neova:taxonomy}.}{1}

\subsection{Aprendizaje supervisado}
\label{aprendizaje-supervisado}

Los algoritmos de aprendizaje supervisado utilizan datos etiquetados durante su proceso de entrenamiento~\cite{david:sl}. Un ejemplo popular de datos etiquetados podría ser un conjunto flores de iris y las posibles etiquetas podrían ser: setosa, versicolor y virginica. Estos datos estarán formados por un conjunto de características (en el caso de las flores de iris podrían ser la longitud y ancho del sépalo y del pétalo). Estas características podrían ser categóricas, continuas o binarias~\cite{salim:sl}.

Para generar un modelo correcto, estos datos son divididos en varios subconjuntos: conjunto de entrenamiento (\textit{training data set}), conjunto de validación (\textit{validation data set}) y conjunto de test (\textit{test data set}). El conjunto de entrenamiento corresponde con la porción de los datos que el algoritmo utilizará para aprender un modelo que generalice los patrones ocultos subyacentes. El conjunto de validación permite comprobar, durante el proceso de entrenamiento, que el modelo que se está generando no memoriza los datos (fenómeno conocido como sobreajuste), también sirve para finalizar el entrenamiento (e.g. el error en validación aumenta durante varias iteraciones). Una vez que el algoritmo ha generado un modelo, se utiliza el conjunto de test para comprobar el rendimiento real (una estimación)~\cite{enwiki:conjuntos}. Ningún dato de este último conjunto ha sido ``visto'' por el modelo previamente.


En la figura~\ref{fig:figuras/AprendizajeSupervisado.PNG} se encuentra un diagrama con el funcionamiento general.

\imagen{figuras/AprendizajeSupervisado.PNG}{Funcionamiento general del aprendizaje supervisado}{Funcionamiento general del aprendizaje supervisado, basado en~\cite{salim:sl}.}{1}

Partiendo del concepto de etiqueta de un dato, el problema será de \textbf{clasificación} si los valores que puede tomar la etiqueta representan un conjunto finito. Por otro lado, si estos valores son continuos, el problema será de \textbf{regresión}.

\begin{itemize}
    \item \textbf{Clasificación}: Un modelo entrenado en un problema de clasificación se denomina clasificador. Ante un nuevo dato, el clasificador predecirá su etiqueta correspondiente. Por lo general, a cada valor de etiqueta se le suele llamar clase. Dependiendo de la cantidad de valores, se referirá a un problema binario o multiclase.

    \item \textbf{Regresión}: En este caso, ante un nuevo dato, el modelo predecirá un valor continuo. La idea subyacente es evaluar una función (ajustada/aprendida durante el entrenamiento) dado un dato como variables de entrada.

\end{itemize}


\subsection{Aprendizaje no supervisado}
\label{aprendizaje-no-supervisado}

A diferencia del aprendizaje supervisado, el no supervisado no trabaja con datos etiquetados y clases. Según~\cite{salim:usl} esto quiere decir que nosotros no ``supervisamos'' el algoritmo. No se le añade ese conocimiento extra. Estos algoritmos intentarán descubrir patrones que se encuentren en la propia estructura de los datos (de sus características). La idea del aprendizaje no supervisado es estudiar las similitudes/disimilitudes que hay entre los datos y, por ejemplo, obtener una separación o agrupación de los mismos (e.g. separación de especies en imágenes de animales sin conocer el animal concreto).
 
A continuación, las principales aplicaciones del aprendizaje no supervisado:
\vspace{-4px}
\begin{enumerate}
    \item \textbf{Agrupamiento (Clustering)}: Este tipo de algoritmo de
    aprendizaje no supervisado trata de dividir los datos en grupos. Para ello,
    estudia las similitudes entre ellos y también en las disimilitudes con
    otros. Estos algoritmos pueden tanto descubrir por ellos mismos los
    <<clústeres>> o grupos que se encuentran o indicarle cuántos debe
    identificar~\cite{salim:usl}.
    \item \textbf{Reducción de la dimensionalidad}: Para empezar, el término
    "<dimensionalidad"> hace referencia al número de variables de entrada que
    tienen los datos. En la realidad, los conjuntos de datos sobre los que se
    trabaja suelen tener una dimensionalidad grande. Según
   ~\cite{javatpoint:reduccionsdims} la reducción de dimensionalidad se denomina
    como: \begin{quote}<<\textit{Una forma de convertir conjuntos de datos de alta dimensionalidad en
    conjunto de datos de menor dimensionalidad, pero garantizando que proporciona
    información similar.}>>\end{quote} Es decir, simplificar el problema pero sin perder
    toda esa estructura interesante de los datos. Algunos ejemplos pueden ser:
    \begin{itemize}
        \item Análisis de Componentes Principales (PCA).
        \item Cuantificación vectorial.
        \item Autoencoders.
    \end{itemize}
\end{enumerate}

\imagenconurl{figuras/Clustering.jpg}{Clusters}{\footnotesize{\emph{Clusters}. Ejemplo de
agrupamiento, a la izquierda los datos no etiquetados y a la derecha los datos
coloreados según las clases identificadas por el algoritmo de clustering. By
hellisp - Own work, Public Domain,
\url{https://commons.wikimedia.org/w/index.php?curid=36929773}. }}{0.7} 

\subsection{Aprendizaje semi-supervisado}
\label{aprendizaje-semi-supervisado}

Según~\cite{vanEngelen2020}, el aprendizaje semi-supervisado es la rama del
aprendizaje automático referido al uso simultáneo de datos tanto etiquetados
como no etiquetados para realizar tareas de aprendizaje. Se encuentra a caballo
entre el aprendizaje supervisado y el no supervisado. Concretamente, los
problemas donde más se aplica, y donde más investigación se realiza es en
clasificación. Los métodos semi-supervisados resultan especialmente útiles
cuando se tienen escasos datos etiquetados, que, aparte de ser una situación
común en problemas reales, hacen que el proceso de etiquetado sea una labor
compleja, que consume tiempo y es costosa.

\subsubsection{Suposiciones}
El objetivo de usar datos no etiquetados es construir un clasificador que sea
mejor que el que se obtendría utilizando aprendizaje supervisado, donde solo se
tienen datos etiquetados. Pero para que el aprendizaje semi-supervisado mejore a
lo ya existente, tiene una serie de suposiciones que han de cumplirse.

En primera instancia se dice que la condición necesaria es que la distribución
$p(x)$ del espacio de entrada contiene información sobre la distribución
posterior $p(y|x)$~\cite{vanEngelen2020}.

Pero la forma en el que interactúan los datos de una distribución y la posterior,
no siempre es la misma:

\begin{mainbox}{Smoothness assumption}
    Esta suposición indica que si dos ejemplos (o instancias) de la entrada
    están cerca en ese espacio de entrada, entonces, probablemente, sus
    etiquetas sean las mismas.
\end{mainbox}

\medskip

\begin{mainbox}{Low-density assumption}
    Esta suposición indica que en clasificación, los límites de decisión deben
    encontrarse en zonas en las que haya pocos de estos ejemplos (o instancias).
\end{mainbox}

\medskip

\begin{mainbox}{Manifold assumption}
    Los datos pueden tener una dimensionalidad alta (muchas características)
    pero generalmente no todas las características son completamente útiles. Los
    datos a menudo se encuentran en unas estructuras de más baja
    dimensionalidad. Estas estructuras se conocen como \emph{manifolds}.
    Esta suposición indica que si los datos del espacio de entrada se encuentran
    en estas \emph{manifolds} entonces aquellos puntos que se encuentren en
    el mismo \emph{manifolds} tendrán la misma etiqueta.
   ~\cite{towardsdatascience:semi,vanEngelen2020}
\end{mainbox}

\medskip

\begin{mainbox}{Cluster assumption}
    Como generalización de las anteriores, aquellos datos que se encuentren en
    un mismo clúster tendrán la misma etiqueta.
\end{mainbox}


De estas suposiciones se extrae el concepto de ``similitud'' que está presente
en todas ellas. Y en realidad, todas son versiones de la \textit{Cluster
assumption}, que dice que los puntos similares tienden a pertenecer al mismo
grupo. 

Además, la suposición de clúster resulta necesaria para que \destacado{el aprendizaje
semi-supervisado mejore al supervisado} (esta es la idea principal del semi-supervisado). Si los datos no pueden ser agrupados,
entonces no mejorará ningún método supervisado~\cite{vanEngelen2020}.


Para tener un punto de vista general, en la figura~\ref{fig:figuras/AprendizajeSemiSupervisado.pdf} se presenta la
taxonomía más general y aceptada de los métodos de aprendizaje semi-supervisado.

\imagen{figuras/AprendizajeSemiSupervisado.pdf}{Taxonomía de métodos semi-supervisados}{Taxonomía de métodos semi-supervisados
~\cite{vanEngelen2020}.}{1}

Sin pérdida de generalidad, este trabajo estará centrado en métodos semi-supervisados basados en grafos y árboles (intrínsecamente semi-supervisados) con la comparación con otros métodos enmarcados en esta taxonomía.

\clearpage
\section{Métodos implementados}

SSLTree